{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"자본분배율(IFRS)\",\"이윤분배율(IFRS)\" ,\"정상영업이익대비이자보상배율(IFRS)\" ], axis=1 , inplace=True)\n",
    "df.dropna(axis=0, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_float = df.select_dtypes(exclude=\"object\")\n",
    "df_float = df[['거래소코드', '총자본증가율(IFRS)', '유형자산증가율(IFRS)', '비유동생물자산증가율(IFRS)',\n",
    "       '투자부동산증가율(IFRS)', '비유동자산증가율(IFRS)', '유동자산증가율(IFRS)', '재고자산증가율(IFRS)',\n",
    "       '자기자본증가율(IFRS)', '매출액증가율(IFRS)']]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i, column in enumerate(df_float.columns):\n",
    "    plt.subplot(5,2,i+1)\n",
    "    plt.title(column)\n",
    "    plt.boxplot(df_float[column])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "for i in df_float.columns:\n",
    "    df_float[i] =  winsorize(df_float[i], limits=[0.05, 0.05])\n",
    "\n",
    "for k in df_float.columns:\n",
    "    df[i] = df_float[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = plt.cm.PuBu\n",
    "upp_mat = np.triu(df.select_dtypes(\"float\").corr(\"pearson\")) #  히트맵의 상삼각 행렬을 만들고, 이를 mask 매개변수로 전달하여 상삼각 행렬 부분을 숨김\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.rcParams['axes.unicode_minus'] = False # matplotlib에서 마이너스 기호 (-)를 제대로 표시하기 위한 설정\n",
    "plt.rc('font', family=\"Malgun Gothic\")\n",
    "plt.title(\"Correlation of Features\", y=1.05, size=15)\n",
    "sns.heatmap(df.select_dtypes(\"float\").corr(\"spearman\"), linewidths=0.1, vmax=1.0, vmin=-1.0, square=True,\n",
    "            cmap=colormap, linecolor=\"white\", annot=True, mask=upp_mat)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
    "vif[\"features\"] = df.columns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20230613\n",
    "\n",
    "for i in range(int(input())):\n",
    "    b, c = map(int,input().split())\n",
    "    print(b+c)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(int(input())//4):\n",
    "    i = \"long\"\n",
    "    print(i, end=\" \")\n",
    "    \n",
    "print(\"int\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif ,mutual_info_classif\n",
    "\n",
    "# f_classif: 분류 작업(classification tasks)에서 레이블(label)과 특징(feature) 사이의 ANOVA F-value를 계산하여 특징을 선택하는 기능을 제공합니다.\n",
    "\n",
    "# mutual_info_classif: 이산형(discrete) 타겟(target)을 위한 상호 정보(mutual information)를 계산하여 특징을 선택하는 기능을 제공합니다.\n",
    "\n",
    "# chi2: 분류 작업(classification tasks)에서 비음수 특징(features)의 카이제곱 통계량(chi-squared statistics)을 계산하여 특징을 선택하는 기능을 제공합니다.\n",
    "\n",
    "# f_regression: 회귀 작업(regression tasks)에서 레이블(label)과 특징(feature) 사이의 ANOVA F-value를 계산하여 특징을 선택하는 기능을 제공합니다.\n",
    "\n",
    "# mutual_info_regression: 연속형(continuous) 타겟(target)을 위한 상호 정보(mutual information)를 계산하여 특징을 선택하는 기능을 제공합니다.\n",
    "\n",
    "# SelectPercentile: 가장 높은 점수에 대한 백분율(percentile)을 기준으로 특징을 선택하는 기능을 제공합니다.\n",
    "\n",
    "# SelectFpr: 거짓 양성 비율(false positive rate) 테스트를 기준으로 특징을 선택하는 기능을 제공합니다.\n",
    "\n",
    "# SelectFdr: 추정된 거짓 발견 비율(false discovery rate)을 기준으로 특징을 선택하는 기능을 제공합니다.\n",
    "\n",
    "# SelectFwe: Family-wise error rate(FWE)를 기준으로 특징을 선택하는 기능을 제공합니다.\n",
    "\n",
    "# GenericUnivariateSelect: 설정 가능한 모드(mode)를 가진 단변량(univariate) 특징 선택기능을 제공합니다.\n",
    "\n",
    "\n",
    "# 아이리스 데이터 로드\n",
    "data = load_iris()\n",
    "X = data.data  # 독립 변수\n",
    "y = data.target  # 종속 변수\n",
    "\n",
    "# SelectKBest를 사용하여 변수 선택\n",
    "k = 2  # 선택할 변수 개수\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df.index = data.feature_names\n",
    "df[\"col\"] = selector.get_support()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression,ElasticNet\n",
    "\n",
    "# 아이리스 데이터 로드\n",
    "iris = load_iris()\n",
    "x_train = iris.data\n",
    "y_train = iris.target\n",
    "\n",
    "# 특성 선택을 저장할 데이터프레임 생성\n",
    "df_select = pd.DataFrame()\n",
    "df_select.index = data.feature_names\n",
    "\n",
    "# L1 규제를 적용한 특성 선택 수행\n",
    "selector = SelectFromModel(estimator=LogisticRegression(penalty='l1', solver='liblinear', C=0.01)).fit(x_train, y_train)\n",
    "df_select[\"lasso_0.01\"] = selector.get_support()\n",
    "\n",
    "selector = SelectFromModel(estimator=LogisticRegression(penalty='l1', solver='liblinear', C=0.05)).fit(x_train, y_train)\n",
    "df_select[\"lasso_0.05\"] = selector.get_support()\n",
    "\n",
    "selector = SelectFromModel(estimator=LogisticRegression(penalty='l1', solver='liblinear', C=0.1)).fit(x_train, y_train)\n",
    "df_select[\"lasso_0.1\"] = selector.get_support()\n",
    "\n",
    "# L2 규제를 적용한 특성 선택 수행\n",
    "selector = SelectFromModel(estimator=LogisticRegression(penalty='l2', solver='liblinear', C=0.01)).fit(x_train, y_train)\n",
    "df_select[\"ridge_0.01\"] = selector.get_support()\n",
    "\n",
    "selector = SelectFromModel(estimator=LogisticRegression(penalty='l2', solver='liblinear', C=0.05)).fit(x_train, y_train)\n",
    "df_select[\"ridge_0.05\"] = selector.get_support()\n",
    "\n",
    "selector = SelectFromModel(estimator=LogisticRegression(penalty='l2', solver='liblinear', C=0.1)).fit(x_train, y_train)\n",
    "df_select[\"ridge_0.1\"] = selector.get_support()\n",
    "\n",
    "# ElasticNet 규제를 적용한 특성 선택 수행\n",
    "selector = SelectFromModel(estimator=ElasticNet(alpha=0.01, l1_ratio=0.5)).fit(x_train, y_train)\n",
    "df_select[\"elasticnet_0.01\"] = selector.get_support()\n",
    "\n",
    "selector = SelectFromModel(estimator=ElasticNet(alpha=0.05, l1_ratio=0.5)).fit(x_train, y_train)\n",
    "df_select[\"elasticnet_0.05\"] = selector.get_support()\n",
    "\n",
    "selector = SelectFromModel(estimator=ElasticNet(alpha=0.1, l1_ratio=0.5)).fit(x_train, y_train)\n",
    "df_select[\"elasticnet_0.1\"] = selector.get_support()\n",
    "\n",
    "# 랜덤 포레스트 분류기 모델 생성 및 훈련\n",
    "selector = SelectFromModel(estimator=RandomForestClassifier(),threshold=0.1).fit(X, y)\n",
    "df_select[\"rf_0.1\"] = selector.get_support()\n",
    "\n",
    "selector = SelectFromModel(estimator=RandomForestClassifier(),threshold=0.1).fit(X, y)\n",
    "df_select[\"rf_0.1\"] = selector.get_support()\n",
    "selector = SelectFromModel(estimator=RandomForestClassifier(),threshold=0.3).fit(X, y)\n",
    "df_select[\"rf_0.3\"] = selector.get_support()\n",
    "\n",
    "\n",
    "df_select[\"true_sum\"] = df_select.sum(axis=1)\n",
    "\n",
    "df_select\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
